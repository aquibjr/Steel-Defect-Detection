{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../3-1/AppofAI/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
    "train_df['HasMask'] = ~ train_df['EncodedPixels'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50272, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>HasMask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels  \\\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...   \n",
       "1  0002cc93b.jpg_2                                                NaN   \n",
       "2  0002cc93b.jpg_3                                                NaN   \n",
       "3  0002cc93b.jpg_4                                                NaN   \n",
       "4  00031f466.jpg_1                                                NaN   \n",
       "\n",
       "         ImageId ClassId  HasMask  \n",
       "0  0002cc93b.jpg       1     True  \n",
       "1  0002cc93b.jpg       2    False  \n",
       "2  0002cc93b.jpg       3    False  \n",
       "3  0002cc93b.jpg       4    False  \n",
       "4  00031f466.jpg       1    False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12568, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>HasMask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>db4867ee8.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11776</th>\n",
       "      <td>ef24da2ba.jpg</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>7f30b9c64.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421</th>\n",
       "      <td>bf0c81db6.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9615</th>\n",
       "      <td>c314f43f3.jpg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  HasMask\n",
       "10803  db4867ee8.jpg      3.0\n",
       "11776  ef24da2ba.jpg      3.0\n",
       "6284   7f30b9c64.jpg      2.0\n",
       "9421   bf0c81db6.jpg      2.0\n",
       "9615   c314f43f3.jpg      2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('HasMask', ascending=False, inplace=True)\n",
    "print(mask_count_df.shape)\n",
    "mask_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../../3-1/AppofAI/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Encoding and Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    \n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(256,1600)):\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    height, width = input_shape\n",
    "    masks = np.zeros((height, width, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, (width, height))\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    \n",
    "    return rles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function - Balanced Cross Entropy + Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator - To load images in batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path='../../3-1/AppofAI/train_images',\n",
    "                 batch_size=32, dim=(256, 1600), n_channels=1,\n",
    "                 n_classes=4, random_state=2019, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = self.__load_grayscale(img_path)\n",
    "            \n",
    "            X[i,] = img\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
    "            \n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            masks = build_masks(rles, input_shape=self.dim)\n",
    "            \n",
    "            y[i, ] = masks\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    mask_count_df.index, random_state=2019, test_size=0.15\n",
    ")\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    train_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    val_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (inputs)\n",
    "    c1 = Conv2D(8, (3, 3), activation='elu', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (p1)\n",
    "    c2 = Conv2D(16, (3, 3), activation='elu', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (p2)\n",
    "    c3 = Conv2D(32, (3, 3), activation='elu', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (p3)\n",
    "    c4 = Conv2D(64, (3, 3), activation='elu', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (p4)\n",
    "    c5 = Conv2D(64, (3, 3), activation='elu', padding='same') (c5)\n",
    "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "\n",
    "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (p5)\n",
    "    c55 = Conv2D(128, (3, 3), activation='elu', padding='same') (c55)\n",
    "    \n",
    "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c55)\n",
    "    u6 = concatenate([u6, c5])\n",
    "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (u6)\n",
    "    c6 = Conv2D(64, (3, 3), activation='elu', padding='same') (c6)\n",
    "\n",
    "    u71 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u71 = concatenate([u71, c4])\n",
    "    c71 = Conv2D(32, (3, 3), activation='elu', padding='same') (u71)\n",
    "    c61 = Conv2D(32, (3, 3), activation='elu', padding='same') (c71)\n",
    "\n",
    "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c61)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (u7)\n",
    "    c7 = Conv2D(32, (3, 3), activation='elu', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (u8)\n",
    "    c8 = Conv2D(16, (3, 3), activation='elu', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (u9)\n",
    "    c9 = Conv2D(8, (3, 3), activation='elu', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aquib\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aquib\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 1600, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 1600, 8) 80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 1600, 8) 584         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 800, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 800, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 800, 16) 2320        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 400, 16)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 400, 32)  4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 400, 32)  9248        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 200, 32)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 200, 64)  18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 200, 64)  36928       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 100, 64)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 100, 64)  36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 50, 64)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 50, 128)   73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 50, 128)   147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 100, 64)  32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 100, 128) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 100, 64)  73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 200, 32)  8224        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 200, 96)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 200, 32)  27680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 200, 32)  9248        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 400, 32)  4128        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 400, 64)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 400, 32)  18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 400, 32)  9248        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 800, 16) 2064        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 800, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 800, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 800, 16) 2320        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 256, 1600, 8) 520         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenate_5 (Concatenate)     (None, 256, 1600, 16 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 1600, 8) 1160        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 1600, 8) 584         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 1600, 4) 36          conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 600,612\n",
      "Trainable params: 600,612\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model((256, 1600, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aquib\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 170/1068 [===>..........................] - ETA: 5:22:09 - loss: 1.7052 - dice_coef: 0.03 - ETA: 4:08:59 - loss: 1.6828 - dice_coef: 0.03 - ETA: 3:44:12 - loss: 1.6646 - dice_coef: 0.02 - ETA: 3:33:18 - loss: 1.6460 - dice_coef: 0.02 - ETA: 3:28:31 - loss: 1.6298 - dice_coef: 0.02 - ETA: 3:22:20 - loss: 1.6059 - dice_coef: 0.02 - ETA: 3:19:52 - loss: 1.5869 - dice_coef: 0.02 - ETA: 3:17:01 - loss: 1.5669 - dice_coef: 0.01 - ETA: 3:14:50 - loss: 1.5426 - dice_coef: 0.01 - ETA: 3:14:55 - loss: 1.5189 - dice_coef: 0.01 - ETA: 3:14:54 - loss: 1.4930 - dice_coef: 0.01 - ETA: 3:12:58 - loss: 1.4674 - dice_coef: 0.01 - ETA: 3:11:08 - loss: 1.4406 - dice_coef: 0.01 - ETA: 3:09:53 - loss: 1.4144 - dice_coef: 0.01 - ETA: 3:09:50 - loss: 1.3916 - dice_coef: 0.01 - ETA: 3:10:20 - loss: 1.3707 - dice_coef: 0.01 - ETA: 3:09:49 - loss: 1.3512 - dice_coef: 0.01 - ETA: 3:09:21 - loss: 1.3348 - dice_coef: 0.01 - ETA: 3:09:46 - loss: 1.3187 - dice_coef: 0.01 - ETA: 3:08:45 - loss: 1.3041 - dice_coef: 0.01 - ETA: 3:07:54 - loss: 1.2911 - dice_coef: 0.01 - ETA: 3:07:21 - loss: 1.2790 - dice_coef: 0.01 - ETA: 3:06:46 - loss: 1.2677 - dice_coef: 0.01 - ETA: 3:05:56 - loss: 1.2595 - dice_coef: 0.01 - ETA: 3:05:16 - loss: 1.2498 - dice_coef: 0.01 - ETA: 3:04:47 - loss: 1.2408 - dice_coef: 0.01 - ETA: 3:04:19 - loss: 1.2323 - dice_coef: 0.01 - ETA: 3:04:32 - loss: 1.2244 - dice_coef: 0.01 - ETA: 3:04:37 - loss: 1.2179 - dice_coef: 0.01 - ETA: 3:04:21 - loss: 1.2110 - dice_coef: 0.01 - ETA: 3:03:39 - loss: 1.2047 - dice_coef: 0.02 - ETA: 3:03:05 - loss: 1.1993 - dice_coef: 0.02 - ETA: 3:02:53 - loss: 1.1959 - dice_coef: 0.02 - ETA: 3:02:24 - loss: 1.1909 - dice_coef: 0.02 - ETA: 3:01:54 - loss: 1.1879 - dice_coef: 0.02 - ETA: 3:01:31 - loss: 1.1827 - dice_coef: 0.02 - ETA: 3:01:27 - loss: 1.1780 - dice_coef: 0.02 - ETA: 3:00:57 - loss: 1.1735 - dice_coef: 0.02 - ETA: 3:00:43 - loss: 1.1690 - dice_coef: 0.02 - ETA: 3:00:20 - loss: 1.1656 - dice_coef: 0.02 - ETA: 3:00:20 - loss: 1.1634 - dice_coef: 0.02 - ETA: 2:59:50 - loss: 1.1601 - dice_coef: 0.02 - ETA: 2:59:30 - loss: 1.1572 - dice_coef: 0.02 - ETA: 2:59:24 - loss: 1.1543 - dice_coef: 0.02 - ETA: 2:59:19 - loss: 1.1519 - dice_coef: 0.02 - ETA: 2:58:58 - loss: 1.1495 - dice_coef: 0.02 - ETA: 2:58:32 - loss: 1.1465 - dice_coef: 0.02 - ETA: 2:58:04 - loss: 1.1437 - dice_coef: 0.02 - ETA: 2:57:43 - loss: 1.1414 - dice_coef: 0.02 - ETA: 2:57:25 - loss: 1.1387 - dice_coef: 0.02 - ETA: 2:57:22 - loss: 1.1364 - dice_coef: 0.02 - ETA: 2:56:57 - loss: 1.1344 - dice_coef: 0.02 - ETA: 2:56:33 - loss: 1.1323 - dice_coef: 0.02 - ETA: 2:56:26 - loss: 1.1310 - dice_coef: 0.02 - ETA: 2:56:02 - loss: 1.1432 - dice_coef: 0.02 - ETA: 2:55:42 - loss: 1.1411 - dice_coef: 0.02 - ETA: 2:55:24 - loss: 1.1388 - dice_coef: 0.02 - ETA: 2:55:03 - loss: 1.1366 - dice_coef: 0.02 - ETA: 2:54:50 - loss: 1.1345 - dice_coef: 0.02 - ETA: 2:54:36 - loss: 1.1324 - dice_coef: 0.02 - ETA: 2:54:23 - loss: 1.1308 - dice_coef: 0.02 - ETA: 2:54:09 - loss: 1.1289 - dice_coef: 0.02 - ETA: 2:54:00 - loss: 1.1271 - dice_coef: 0.02 - ETA: 2:53:48 - loss: 1.1259 - dice_coef: 0.02 - ETA: 2:53:34 - loss: 1.1242 - dice_coef: 0.02 - ETA: 2:53:20 - loss: 1.1227 - dice_coef: 0.02 - ETA: 2:53:09 - loss: 1.1210 - dice_coef: 0.02 - ETA: 2:53:01 - loss: 1.1193 - dice_coef: 0.02 - ETA: 2:52:49 - loss: 1.1180 - dice_coef: 0.02 - ETA: 2:52:38 - loss: 1.1165 - dice_coef: 0.02 - ETA: 2:52:26 - loss: 1.1152 - dice_coef: 0.02 - ETA: 2:52:13 - loss: 1.1141 - dice_coef: 0.02 - ETA: 2:52:00 - loss: 1.1128 - dice_coef: 0.02 - ETA: 2:51:48 - loss: 1.1114 - dice_coef: 0.02 - ETA: 2:51:38 - loss: 1.1101 - dice_coef: 0.02 - ETA: 2:51:25 - loss: 1.1091 - dice_coef: 0.02 - ETA: 2:51:13 - loss: 1.1081 - dice_coef: 0.02 - ETA: 2:51:00 - loss: 1.1068 - dice_coef: 0.02 - ETA: 2:50:49 - loss: 1.1058 - dice_coef: 0.02 - ETA: 2:50:43 - loss: 1.1048 - dice_coef: 0.02 - ETA: 2:50:34 - loss: 1.1040 - dice_coef: 0.02 - ETA: 2:50:22 - loss: 1.1028 - dice_coef: 0.02 - ETA: 2:50:11 - loss: 1.1019 - dice_coef: 0.02 - ETA: 2:49:59 - loss: 1.1007 - dice_coef: 0.02 - ETA: 2:49:47 - loss: 1.0999 - dice_coef: 0.02 - ETA: 2:49:39 - loss: 1.0988 - dice_coef: 0.02 - ETA: 2:49:27 - loss: 1.0977 - dice_coef: 0.02 - ETA: 2:49:09 - loss: 1.0967 - dice_coef: 0.02 - ETA: 2:48:53 - loss: 1.0965 - dice_coef: 0.02 - ETA: 2:48:41 - loss: 1.0956 - dice_coef: 0.02 - ETA: 2:48:29 - loss: 1.0946 - dice_coef: 0.02 - ETA: 2:48:20 - loss: 1.0938 - dice_coef: 0.02 - ETA: 2:48:09 - loss: 1.0929 - dice_coef: 0.02 - ETA: 2:47:58 - loss: 1.0920 - dice_coef: 0.02 - ETA: 2:47:45 - loss: 1.0915 - dice_coef: 0.02 - ETA: 2:47:35 - loss: 1.0907 - dice_coef: 0.02 - ETA: 2:47:23 - loss: 1.0898 - dice_coef: 0.02 - ETA: 2:47:14 - loss: 1.0892 - dice_coef: 0.02 - ETA: 2:47:02 - loss: 1.0885 - dice_coef: 0.02 - ETA: 2:46:50 - loss: 1.0878 - dice_coef: 0.02 - ETA: 2:46:39 - loss: 1.0872 - dice_coef: 0.02 - ETA: 2:46:27 - loss: 1.0865 - dice_coef: 0.02 - ETA: 2:46:18 - loss: 1.0856 - dice_coef: 0.02 - ETA: 2:46:08 - loss: 1.0849 - dice_coef: 0.02 - ETA: 2:45:56 - loss: 1.0841 - dice_coef: 0.02 - ETA: 2:45:45 - loss: 1.0849 - dice_coef: 0.02 - ETA: 2:45:33 - loss: 1.0844 - dice_coef: 0.02 - ETA: 2:45:22 - loss: 1.0836 - dice_coef: 0.02 - ETA: 2:45:11 - loss: 1.0831 - dice_coef: 0.02 - ETA: 2:45:01 - loss: 1.0824 - dice_coef: 0.02 - ETA: 2:44:50 - loss: 1.0820 - dice_coef: 0.02 - ETA: 2:44:39 - loss: 1.0816 - dice_coef: 0.02 - ETA: 2:44:28 - loss: 1.0809 - dice_coef: 0.02 - ETA: 2:44:16 - loss: 1.0803 - dice_coef: 0.02 - ETA: 2:44:09 - loss: 1.0796 - dice_coef: 0.02 - ETA: 2:43:58 - loss: 1.0791 - dice_coef: 0.02 - ETA: 2:43:47 - loss: 1.0785 - dice_coef: 0.02 - ETA: 2:43:37 - loss: 1.0780 - dice_coef: 0.02 - ETA: 2:43:25 - loss: 1.0774 - dice_coef: 0.02 - ETA: 2:43:15 - loss: 1.0768 - dice_coef: 0.02 - ETA: 2:43:03 - loss: 1.0765 - dice_coef: 0.02 - ETA: 2:42:54 - loss: 1.0759 - dice_coef: 0.02 - ETA: 2:42:42 - loss: 1.0755 - dice_coef: 0.02 - ETA: 2:42:30 - loss: 1.0752 - dice_coef: 0.02 - ETA: 2:42:19 - loss: 1.0749 - dice_coef: 0.02 - ETA: 2:42:08 - loss: 1.0745 - dice_coef: 0.02 - ETA: 2:41:59 - loss: 1.0740 - dice_coef: 0.02 - ETA: 2:41:48 - loss: 1.0735 - dice_coef: 0.02 - ETA: 2:41:38 - loss: 1.0730 - dice_coef: 0.02 - ETA: 2:41:27 - loss: 1.0727 - dice_coef: 0.02 - ETA: 2:41:15 - loss: 1.0721 - dice_coef: 0.02 - ETA: 2:41:04 - loss: 1.0717 - dice_coef: 0.02 - ETA: 2:40:54 - loss: 1.0711 - dice_coef: 0.02 - ETA: 2:40:43 - loss: 1.0707 - dice_coef: 0.02 - ETA: 2:40:33 - loss: 1.0702 - dice_coef: 0.02 - ETA: 2:40:20 - loss: 1.0700 - dice_coef: 0.02 - ETA: 2:40:10 - loss: 1.0695 - dice_coef: 0.02 - ETA: 2:40:00 - loss: 1.0692 - dice_coef: 0.02 - ETA: 2:40:09 - loss: 1.0687 - dice_coef: 0.02 - ETA: 2:40:09 - loss: 1.0684 - dice_coef: 0.02 - ETA: 2:40:09 - loss: 1.0681 - dice_coef: 0.02 - ETA: 2:39:57 - loss: 1.0678 - dice_coef: 0.02 - ETA: 2:39:45 - loss: 1.0676 - dice_coef: 0.02 - ETA: 2:39:31 - loss: 1.0672 - dice_coef: 0.02 - ETA: 2:39:18 - loss: 1.0668 - dice_coef: 0.02 - ETA: 2:39:06 - loss: 1.0665 - dice_coef: 0.02 - ETA: 2:38:56 - loss: 1.0662 - dice_coef: 0.02 - ETA: 2:38:45 - loss: 1.0658 - dice_coef: 0.02 - ETA: 2:38:33 - loss: 1.0655 - dice_coef: 0.02 - ETA: 2:38:24 - loss: 1.0651 - dice_coef: 0.02 - ETA: 2:38:15 - loss: 1.0648 - dice_coef: 0.02 - ETA: 2:38:05 - loss: 1.0644 - dice_coef: 0.02 - ETA: 2:37:53 - loss: 1.0640 - dice_coef: 0.02 - ETA: 2:37:42 - loss: 1.0636 - dice_coef: 0.02 - ETA: 2:37:32 - loss: 1.0632 - dice_coef: 0.02 - ETA: 2:37:22 - loss: 1.0629 - dice_coef: 0.02 - ETA: 2:37:11 - loss: 1.0627 - dice_coef: 0.02 - ETA: 2:36:59 - loss: 1.0624 - dice_coef: 0.02 - ETA: 2:36:49 - loss: 1.0620 - dice_coef: 0.02 - ETA: 2:36:37 - loss: 1.0617 - dice_coef: 0.02 - ETA: 2:36:28 - loss: 1.0614 - dice_coef: 0.02 - ETA: 2:36:18 - loss: 1.0611 - dice_coef: 0.02 - ETA: 2:36:06 - loss: 1.0608 - dice_coef: 0.02 - ETA: 2:35:56 - loss: 1.0605 - dice_coef: 0.02 - ETA: 2:35:45 - loss: 1.0601 - dice_coef: 0.02 - ETA: 2:35:33 - loss: 1.0598 - dice_coef: 0.02 - ETA: 2:35:22 - loss: 1.0595 - dice_coef: 0.02 - ETA: 2:35:13 - loss: 1.0593 - dice_coef: 0.02 - ETA: 2:35:01 - loss: 1.0590 - dice_coef: 0.02 - ETA: 2:34:52 - loss: 1.0587 - dice_coef: 0.0256"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 340/1068 [========>.....................] - ETA: 2:34:41 - loss: 1.0588 - dice_coef: 0.02 - ETA: 2:34:30 - loss: 1.0587 - dice_coef: 0.02 - ETA: 2:34:20 - loss: 1.0585 - dice_coef: 0.02 - ETA: 2:34:09 - loss: 1.0582 - dice_coef: 0.02 - ETA: 2:33:59 - loss: 1.0579 - dice_coef: 0.02 - ETA: 2:33:48 - loss: 1.0578 - dice_coef: 0.02 - ETA: 2:33:38 - loss: 1.0575 - dice_coef: 0.02 - ETA: 2:33:27 - loss: 1.0577 - dice_coef: 0.02 - ETA: 2:33:16 - loss: 1.0574 - dice_coef: 0.02 - ETA: 2:33:06 - loss: 1.0573 - dice_coef: 0.02 - ETA: 2:32:55 - loss: 1.0572 - dice_coef: 0.02 - ETA: 2:32:44 - loss: 1.0570 - dice_coef: 0.02 - ETA: 2:32:33 - loss: 1.0567 - dice_coef: 0.02 - ETA: 2:32:23 - loss: 1.0566 - dice_coef: 0.02 - ETA: 2:32:14 - loss: 1.0564 - dice_coef: 0.02 - ETA: 2:32:03 - loss: 1.0560 - dice_coef: 0.02 - ETA: 2:31:52 - loss: 1.0557 - dice_coef: 0.02 - ETA: 2:31:40 - loss: 1.0555 - dice_coef: 0.02 - ETA: 2:31:29 - loss: 1.0555 - dice_coef: 0.02 - ETA: 2:31:18 - loss: 1.0553 - dice_coef: 0.02 - ETA: 2:31:08 - loss: 1.0551 - dice_coef: 0.02 - ETA: 2:30:57 - loss: 1.0548 - dice_coef: 0.02 - ETA: 2:30:45 - loss: 1.0546 - dice_coef: 0.02 - ETA: 2:30:34 - loss: 1.0544 - dice_coef: 0.02 - ETA: 2:30:23 - loss: 1.0543 - dice_coef: 0.02 - ETA: 2:30:13 - loss: 1.0541 - dice_coef: 0.02 - ETA: 2:30:03 - loss: 1.0540 - dice_coef: 0.02 - ETA: 2:29:51 - loss: 1.0538 - dice_coef: 0.02 - ETA: 2:29:42 - loss: 1.0536 - dice_coef: 0.02 - ETA: 2:29:32 - loss: 1.0535 - dice_coef: 0.02 - ETA: 2:29:20 - loss: 1.0534 - dice_coef: 0.02 - ETA: 2:29:07 - loss: 1.0532 - dice_coef: 0.02 - ETA: 2:28:54 - loss: 1.0530 - dice_coef: 0.02 - ETA: 2:28:43 - loss: 1.0530 - dice_coef: 0.02 - ETA: 2:28:31 - loss: 1.0528 - dice_coef: 0.02 - ETA: 2:28:18 - loss: 1.0526 - dice_coef: 0.02 - ETA: 2:28:05 - loss: 1.0524 - dice_coef: 0.02 - ETA: 2:27:55 - loss: 1.0523 - dice_coef: 0.02 - ETA: 2:27:45 - loss: 1.0521 - dice_coef: 0.02 - ETA: 2:27:34 - loss: 1.0519 - dice_coef: 0.02 - ETA: 2:27:23 - loss: 1.0517 - dice_coef: 0.02 - ETA: 2:27:12 - loss: 1.0515 - dice_coef: 0.02 - ETA: 2:27:01 - loss: 1.0513 - dice_coef: 0.02 - ETA: 2:26:51 - loss: 1.0512 - dice_coef: 0.02 - ETA: 2:26:41 - loss: 1.0510 - dice_coef: 0.02 - ETA: 2:26:32 - loss: 1.0508 - dice_coef: 0.02 - ETA: 2:26:21 - loss: 1.0507 - dice_coef: 0.02 - ETA: 2:26:10 - loss: 1.0504 - dice_coef: 0.02 - ETA: 2:26:00 - loss: 1.0502 - dice_coef: 0.02 - ETA: 2:25:50 - loss: 1.0500 - dice_coef: 0.02 - ETA: 2:25:40 - loss: 1.0500 - dice_coef: 0.02 - ETA: 2:25:29 - loss: 1.0497 - dice_coef: 0.02 - ETA: 2:25:18 - loss: 1.0496 - dice_coef: 0.02 - ETA: 2:25:06 - loss: 1.0494 - dice_coef: 0.02 - ETA: 2:24:53 - loss: 1.0493 - dice_coef: 0.02 - ETA: 2:24:40 - loss: 1.0491 - dice_coef: 0.02 - ETA: 2:24:30 - loss: 1.0488 - dice_coef: 0.02 - ETA: 2:24:19 - loss: 1.0487 - dice_coef: 0.02 - ETA: 2:24:08 - loss: 1.0486 - dice_coef: 0.02 - ETA: 2:23:58 - loss: 1.0487 - dice_coef: 0.02 - ETA: 2:23:47 - loss: 1.0485 - dice_coef: 0.02 - ETA: 2:23:37 - loss: 1.0483 - dice_coef: 0.02 - ETA: 2:23:26 - loss: 1.0484 - dice_coef: 0.02 - ETA: 2:23:16 - loss: 1.0483 - dice_coef: 0.02 - ETA: 2:23:05 - loss: 1.0481 - dice_coef: 0.02 - ETA: 2:22:54 - loss: 1.0481 - dice_coef: 0.02 - ETA: 2:22:44 - loss: 1.0480 - dice_coef: 0.02 - ETA: 2:22:33 - loss: 1.0478 - dice_coef: 0.02 - ETA: 2:22:23 - loss: 1.0477 - dice_coef: 0.02 - ETA: 2:22:12 - loss: 1.0475 - dice_coef: 0.02 - ETA: 2:22:02 - loss: 1.0474 - dice_coef: 0.02 - ETA: 2:21:51 - loss: 1.0472 - dice_coef: 0.02 - ETA: 2:21:41 - loss: 1.0470 - dice_coef: 0.02 - ETA: 2:21:31 - loss: 1.0468 - dice_coef: 0.02 - ETA: 2:21:21 - loss: 1.0467 - dice_coef: 0.02 - ETA: 2:21:11 - loss: 1.0465 - dice_coef: 0.02 - ETA: 2:21:00 - loss: 1.0463 - dice_coef: 0.02 - ETA: 2:20:49 - loss: 1.0462 - dice_coef: 0.02 - ETA: 2:20:39 - loss: 1.0460 - dice_coef: 0.02 - ETA: 2:20:30 - loss: 1.0458 - dice_coef: 0.02 - ETA: 2:20:20 - loss: 1.0457 - dice_coef: 0.02 - ETA: 2:20:10 - loss: 1.0455 - dice_coef: 0.02 - ETA: 2:19:58 - loss: 1.0454 - dice_coef: 0.02 - ETA: 2:19:46 - loss: 1.0452 - dice_coef: 0.02 - ETA: 2:19:35 - loss: 1.0450 - dice_coef: 0.02 - ETA: 2:19:24 - loss: 1.0450 - dice_coef: 0.02 - ETA: 2:19:13 - loss: 1.0449 - dice_coef: 0.02 - ETA: 2:19:03 - loss: 1.0447 - dice_coef: 0.02 - ETA: 2:18:52 - loss: 1.0445 - dice_coef: 0.02 - ETA: 2:18:42 - loss: 1.0444 - dice_coef: 0.02 - ETA: 2:18:31 - loss: 1.0443 - dice_coef: 0.02 - ETA: 2:18:21 - loss: 1.0443 - dice_coef: 0.02 - ETA: 2:18:11 - loss: 1.0441 - dice_coef: 0.02 - ETA: 2:18:00 - loss: 1.0441 - dice_coef: 0.02 - ETA: 2:17:49 - loss: 1.0439 - dice_coef: 0.02 - ETA: 2:17:38 - loss: 1.0438 - dice_coef: 0.02 - ETA: 2:17:29 - loss: 1.0436 - dice_coef: 0.02 - ETA: 2:17:19 - loss: 1.0434 - dice_coef: 0.02 - ETA: 2:17:08 - loss: 1.0435 - dice_coef: 0.02 - ETA: 2:16:57 - loss: 1.0433 - dice_coef: 0.02 - ETA: 2:16:47 - loss: 1.0434 - dice_coef: 0.02 - ETA: 2:16:37 - loss: 1.0432 - dice_coef: 0.02 - ETA: 2:16:26 - loss: 1.0431 - dice_coef: 0.02 - ETA: 2:16:15 - loss: 1.0431 - dice_coef: 0.02 - ETA: 2:16:06 - loss: 1.0430 - dice_coef: 0.02 - ETA: 2:15:54 - loss: 1.0430 - dice_coef: 0.02 - ETA: 2:15:42 - loss: 1.0429 - dice_coef: 0.02 - ETA: 2:15:31 - loss: 1.0428 - dice_coef: 0.02 - ETA: 2:15:21 - loss: 1.0426 - dice_coef: 0.02 - ETA: 2:15:10 - loss: 1.0425 - dice_coef: 0.02 - ETA: 2:15:01 - loss: 1.0424 - dice_coef: 0.02 - ETA: 2:14:50 - loss: 1.0423 - dice_coef: 0.02 - ETA: 2:14:39 - loss: 1.0422 - dice_coef: 0.02 - ETA: 2:14:28 - loss: 1.0421 - dice_coef: 0.02 - ETA: 2:14:18 - loss: 1.0422 - dice_coef: 0.02 - ETA: 2:14:08 - loss: 1.0421 - dice_coef: 0.02 - ETA: 2:13:58 - loss: 1.0420 - dice_coef: 0.02 - ETA: 2:13:47 - loss: 1.0419 - dice_coef: 0.02 - ETA: 2:13:36 - loss: 1.0417 - dice_coef: 0.02 - ETA: 2:13:26 - loss: 1.0417 - dice_coef: 0.02 - ETA: 2:13:16 - loss: 1.0416 - dice_coef: 0.02 - ETA: 2:13:06 - loss: 1.0415 - dice_coef: 0.02 - ETA: 2:12:56 - loss: 1.0414 - dice_coef: 0.02 - ETA: 2:12:45 - loss: 1.0413 - dice_coef: 0.02 - ETA: 2:12:34 - loss: 1.0412 - dice_coef: 0.02 - ETA: 2:12:24 - loss: 1.0411 - dice_coef: 0.02 - ETA: 2:12:14 - loss: 1.0410 - dice_coef: 0.02 - ETA: 2:12:03 - loss: 1.0409 - dice_coef: 0.02 - ETA: 2:11:53 - loss: 1.0408 - dice_coef: 0.02 - ETA: 2:11:43 - loss: 1.0407 - dice_coef: 0.02 - ETA: 2:11:33 - loss: 1.0406 - dice_coef: 0.02 - ETA: 2:11:23 - loss: 1.0406 - dice_coef: 0.02 - ETA: 2:11:13 - loss: 1.0406 - dice_coef: 0.02 - ETA: 2:11:02 - loss: 1.0406 - dice_coef: 0.02 - ETA: 2:10:52 - loss: 1.0405 - dice_coef: 0.02 - ETA: 2:10:42 - loss: 1.0404 - dice_coef: 0.02 - ETA: 2:10:31 - loss: 1.0403 - dice_coef: 0.02 - ETA: 2:10:21 - loss: 1.0402 - dice_coef: 0.02 - ETA: 2:10:11 - loss: 1.0400 - dice_coef: 0.02 - ETA: 2:10:00 - loss: 1.0400 - dice_coef: 0.02 - ETA: 2:09:49 - loss: 1.0399 - dice_coef: 0.02 - ETA: 2:09:37 - loss: 1.0399 - dice_coef: 0.02 - ETA: 2:09:26 - loss: 1.0397 - dice_coef: 0.02 - ETA: 2:09:16 - loss: 1.0397 - dice_coef: 0.02 - ETA: 2:09:05 - loss: 1.0396 - dice_coef: 0.02 - ETA: 2:08:55 - loss: 1.0396 - dice_coef: 0.02 - ETA: 2:08:44 - loss: 1.0395 - dice_coef: 0.02 - ETA: 2:08:34 - loss: 1.0394 - dice_coef: 0.02 - ETA: 2:08:23 - loss: 1.0394 - dice_coef: 0.02 - ETA: 2:08:13 - loss: 1.0393 - dice_coef: 0.02 - ETA: 2:08:04 - loss: 1.0392 - dice_coef: 0.02 - ETA: 2:07:53 - loss: 1.0392 - dice_coef: 0.02 - ETA: 2:07:42 - loss: 1.0391 - dice_coef: 0.02 - ETA: 2:07:32 - loss: 1.0391 - dice_coef: 0.02 - ETA: 2:07:21 - loss: 1.0390 - dice_coef: 0.02 - ETA: 2:07:11 - loss: 1.0389 - dice_coef: 0.02 - ETA: 2:07:01 - loss: 1.0388 - dice_coef: 0.02 - ETA: 2:06:51 - loss: 1.0387 - dice_coef: 0.02 - ETA: 2:06:40 - loss: 1.0386 - dice_coef: 0.02 - ETA: 2:06:29 - loss: 1.0385 - dice_coef: 0.02 - ETA: 2:06:20 - loss: 1.0385 - dice_coef: 0.02 - ETA: 2:06:10 - loss: 1.0384 - dice_coef: 0.02 - ETA: 2:05:59 - loss: 1.0383 - dice_coef: 0.02 - ETA: 2:05:49 - loss: 1.0383 - dice_coef: 0.02 - ETA: 2:05:39 - loss: 1.0382 - dice_coef: 0.02 - ETA: 2:05:28 - loss: 1.0382 - dice_coef: 0.02 - ETA: 2:05:18 - loss: 1.0381 - dice_coef: 0.02 - ETA: 2:05:08 - loss: 1.0380 - dice_coef: 0.02 - ETA: 2:04:58 - loss: 1.0380 - dice_coef: 0.02 - ETA: 2:04:47 - loss: 1.0379 - dice_coef: 0.0291"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 510/1068 [=============>................] - ETA: 2:04:37 - loss: 1.0378 - dice_coef: 0.02 - ETA: 2:04:26 - loss: 1.0378 - dice_coef: 0.02 - ETA: 2:04:16 - loss: 1.0377 - dice_coef: 0.02 - ETA: 2:04:06 - loss: 1.0376 - dice_coef: 0.02 - ETA: 2:03:55 - loss: 1.0375 - dice_coef: 0.02 - ETA: 2:03:45 - loss: 1.0374 - dice_coef: 0.02 - ETA: 2:03:34 - loss: 1.0375 - dice_coef: 0.02 - ETA: 2:03:24 - loss: 1.0374 - dice_coef: 0.02 - ETA: 2:03:14 - loss: 1.0373 - dice_coef: 0.02 - ETA: 2:03:03 - loss: 1.0373 - dice_coef: 0.02 - ETA: 2:02:52 - loss: 1.0373 - dice_coef: 0.02 - ETA: 2:02:40 - loss: 1.0372 - dice_coef: 0.02 - ETA: 2:02:30 - loss: 1.0372 - dice_coef: 0.02 - ETA: 2:02:19 - loss: 1.0371 - dice_coef: 0.02 - ETA: 2:02:09 - loss: 1.0369 - dice_coef: 0.02 - ETA: 2:01:59 - loss: 1.0369 - dice_coef: 0.02 - ETA: 2:01:49 - loss: 1.0369 - dice_coef: 0.02 - ETA: 2:01:38 - loss: 1.0368 - dice_coef: 0.02 - ETA: 2:01:27 - loss: 1.0367 - dice_coef: 0.02 - ETA: 2:01:17 - loss: 1.0366 - dice_coef: 0.02 - ETA: 2:01:07 - loss: 1.0365 - dice_coef: 0.02 - ETA: 2:00:57 - loss: 1.0366 - dice_coef: 0.02 - ETA: 2:00:47 - loss: 1.0365 - dice_coef: 0.02 - ETA: 2:00:37 - loss: 1.0365 - dice_coef: 0.02 - ETA: 2:00:26 - loss: 1.0364 - dice_coef: 0.02 - ETA: 2:00:16 - loss: 1.0364 - dice_coef: 0.02 - ETA: 2:00:05 - loss: 1.0363 - dice_coef: 0.02 - ETA: 1:59:55 - loss: 1.0362 - dice_coef: 0.02 - ETA: 1:59:45 - loss: 1.0361 - dice_coef: 0.02 - ETA: 1:59:34 - loss: 1.0360 - dice_coef: 0.02 - ETA: 1:59:24 - loss: 1.0359 - dice_coef: 0.02 - ETA: 1:59:14 - loss: 1.0358 - dice_coef: 0.02 - ETA: 1:59:04 - loss: 1.0357 - dice_coef: 0.02 - ETA: 1:58:55 - loss: 1.0356 - dice_coef: 0.02 - ETA: 1:58:45 - loss: 1.0356 - dice_coef: 0.02 - ETA: 1:58:34 - loss: 1.0355 - dice_coef: 0.02 - ETA: 1:58:24 - loss: 1.0354 - dice_coef: 0.02 - ETA: 1:58:13 - loss: 1.0353 - dice_coef: 0.02 - ETA: 1:58:03 - loss: 1.0353 - dice_coef: 0.02 - ETA: 1:57:53 - loss: 1.0352 - dice_coef: 0.02 - ETA: 1:57:42 - loss: 1.0351 - dice_coef: 0.02 - ETA: 1:57:32 - loss: 1.0350 - dice_coef: 0.02 - ETA: 1:57:21 - loss: 1.0350 - dice_coef: 0.02 - ETA: 1:57:12 - loss: 1.0350 - dice_coef: 0.02 - ETA: 1:57:01 - loss: 1.0350 - dice_coef: 0.02 - ETA: 1:56:51 - loss: 1.0351 - dice_coef: 0.02 - ETA: 1:56:40 - loss: 1.0351 - dice_coef: 0.02 - ETA: 1:56:30 - loss: 1.0350 - dice_coef: 0.02 - ETA: 1:56:20 - loss: 1.0349 - dice_coef: 0.02 - ETA: 1:56:09 - loss: 1.0349 - dice_coef: 0.02 - ETA: 1:55:58 - loss: 1.0348 - dice_coef: 0.02 - ETA: 1:55:47 - loss: 1.0348 - dice_coef: 0.02 - ETA: 1:55:37 - loss: 1.0347 - dice_coef: 0.02 - ETA: 1:55:26 - loss: 1.0346 - dice_coef: 0.02 - ETA: 1:55:16 - loss: 1.0345 - dice_coef: 0.02 - ETA: 1:55:06 - loss: 1.0344 - dice_coef: 0.02 - ETA: 1:54:56 - loss: 1.0344 - dice_coef: 0.02 - ETA: 1:54:46 - loss: 1.0344 - dice_coef: 0.02 - ETA: 1:54:35 - loss: 1.0343 - dice_coef: 0.02 - ETA: 1:54:25 - loss: 1.0343 - dice_coef: 0.02 - ETA: 1:54:14 - loss: 1.0342 - dice_coef: 0.02 - ETA: 1:54:04 - loss: 1.0342 - dice_coef: 0.02 - ETA: 1:53:54 - loss: 1.0342 - dice_coef: 0.02 - ETA: 1:53:43 - loss: 1.0341 - dice_coef: 0.02 - ETA: 1:53:33 - loss: 1.0341 - dice_coef: 0.02 - ETA: 1:53:22 - loss: 1.0341 - dice_coef: 0.02 - ETA: 1:53:12 - loss: 1.0340 - dice_coef: 0.02 - ETA: 1:53:02 - loss: 1.0339 - dice_coef: 0.02 - ETA: 1:52:52 - loss: 1.0338 - dice_coef: 0.02 - ETA: 1:52:42 - loss: 1.0338 - dice_coef: 0.02 - ETA: 1:52:31 - loss: 1.0337 - dice_coef: 0.02 - ETA: 1:52:21 - loss: 1.0336 - dice_coef: 0.02 - ETA: 1:52:10 - loss: 1.0335 - dice_coef: 0.02 - ETA: 1:52:01 - loss: 1.0335 - dice_coef: 0.02 - ETA: 1:51:52 - loss: 1.0335 - dice_coef: 0.02 - ETA: 1:51:41 - loss: 1.0335 - dice_coef: 0.02 - ETA: 1:51:31 - loss: 1.0334 - dice_coef: 0.02 - ETA: 1:51:20 - loss: 1.0334 - dice_coef: 0.02 - ETA: 1:51:11 - loss: 1.0334 - dice_coef: 0.02 - ETA: 1:51:01 - loss: 1.0333 - dice_coef: 0.02 - ETA: 1:50:51 - loss: 1.0333 - dice_coef: 0.02 - ETA: 1:50:41 - loss: 1.0332 - dice_coef: 0.02 - ETA: 1:50:30 - loss: 1.0332 - dice_coef: 0.02 - ETA: 1:50:20 - loss: 1.0332 - dice_coef: 0.02 - ETA: 1:50:10 - loss: 1.0331 - dice_coef: 0.02 - ETA: 1:49:59 - loss: 1.0330 - dice_coef: 0.02 - ETA: 1:49:49 - loss: 1.0329 - dice_coef: 0.02 - ETA: 1:49:38 - loss: 1.0329 - dice_coef: 0.02 - ETA: 1:49:28 - loss: 1.0328 - dice_coef: 0.03 - ETA: 1:49:18 - loss: 1.0329 - dice_coef: 0.03 - ETA: 1:49:08 - loss: 1.0327 - dice_coef: 0.03 - ETA: 1:48:57 - loss: 1.0329 - dice_coef: 0.03 - ETA: 1:48:47 - loss: 1.0328 - dice_coef: 0.03 - ETA: 1:48:36 - loss: 1.0328 - dice_coef: 0.03 - ETA: 1:48:26 - loss: 1.0328 - dice_coef: 0.03 - ETA: 1:48:16 - loss: 1.0327 - dice_coef: 0.03 - ETA: 1:48:05 - loss: 1.0327 - dice_coef: 0.03 - ETA: 1:47:55 - loss: 1.0327 - dice_coef: 0.03 - ETA: 1:47:45 - loss: 1.0326 - dice_coef: 0.03 - ETA: 1:47:34 - loss: 1.0325 - dice_coef: 0.03 - ETA: 1:47:24 - loss: 1.0325 - dice_coef: 0.03 - ETA: 1:47:14 - loss: 1.0324 - dice_coef: 0.03 - ETA: 1:47:04 - loss: 1.0324 - dice_coef: 0.03 - ETA: 1:46:53 - loss: 1.0324 - dice_coef: 0.03 - ETA: 1:46:43 - loss: 1.0324 - dice_coef: 0.03 - ETA: 1:46:32 - loss: 1.0323 - dice_coef: 0.03 - ETA: 1:46:22 - loss: 1.0323 - dice_coef: 0.03 - ETA: 1:46:11 - loss: 1.0323 - dice_coef: 0.03 - ETA: 1:46:00 - loss: 1.0322 - dice_coef: 0.03 - ETA: 1:45:49 - loss: 1.0322 - dice_coef: 0.03 - ETA: 1:45:38 - loss: 1.0321 - dice_coef: 0.03 - ETA: 1:45:27 - loss: 1.0321 - dice_coef: 0.03 - ETA: 1:45:16 - loss: 1.0320 - dice_coef: 0.03 - ETA: 1:45:05 - loss: 1.0320 - dice_coef: 0.03 - ETA: 1:44:54 - loss: 1.0319 - dice_coef: 0.03 - ETA: 1:44:43 - loss: 1.0318 - dice_coef: 0.03 - ETA: 1:44:32 - loss: 1.0318 - dice_coef: 0.03 - ETA: 1:44:20 - loss: 1.0319 - dice_coef: 0.03 - ETA: 1:44:09 - loss: 1.0319 - dice_coef: 0.03 - ETA: 1:43:58 - loss: 1.0318 - dice_coef: 0.03 - ETA: 1:43:47 - loss: 1.0318 - dice_coef: 0.03 - ETA: 1:43:36 - loss: 1.0318 - dice_coef: 0.03 - ETA: 1:43:25 - loss: 1.0317 - dice_coef: 0.03 - ETA: 1:43:14 - loss: 1.0316 - dice_coef: 0.03 - ETA: 1:43:03 - loss: 1.0316 - dice_coef: 0.03 - ETA: 1:42:52 - loss: 1.0315 - dice_coef: 0.03 - ETA: 1:42:41 - loss: 1.0315 - dice_coef: 0.03 - ETA: 1:42:30 - loss: 1.0315 - dice_coef: 0.03 - ETA: 1:42:19 - loss: 1.0314 - dice_coef: 0.03 - ETA: 1:42:08 - loss: 1.0314 - dice_coef: 0.03 - ETA: 1:41:57 - loss: 1.0313 - dice_coef: 0.03 - ETA: 1:41:46 - loss: 1.0313 - dice_coef: 0.03 - ETA: 1:41:35 - loss: 1.0312 - dice_coef: 0.03 - ETA: 1:41:24 - loss: 1.0312 - dice_coef: 0.03 - ETA: 1:41:13 - loss: 1.0312 - dice_coef: 0.03 - ETA: 1:41:02 - loss: 1.0311 - dice_coef: 0.03 - ETA: 1:40:51 - loss: 1.0311 - dice_coef: 0.03 - ETA: 1:40:41 - loss: 1.0310 - dice_coef: 0.03 - ETA: 1:40:30 - loss: 1.0310 - dice_coef: 0.03 - ETA: 1:40:19 - loss: 1.0309 - dice_coef: 0.03 - ETA: 1:40:08 - loss: 1.0309 - dice_coef: 0.03 - ETA: 1:39:57 - loss: 1.0309 - dice_coef: 0.03 - ETA: 1:39:46 - loss: 1.0309 - dice_coef: 0.03 - ETA: 1:39:35 - loss: 1.0308 - dice_coef: 0.03 - ETA: 1:39:24 - loss: 1.0308 - dice_coef: 0.03 - ETA: 1:39:14 - loss: 1.0307 - dice_coef: 0.03 - ETA: 1:39:03 - loss: 1.0307 - dice_coef: 0.03 - ETA: 1:38:52 - loss: 1.0306 - dice_coef: 0.03 - ETA: 1:38:41 - loss: 1.0306 - dice_coef: 0.03 - ETA: 1:38:30 - loss: 1.0305 - dice_coef: 0.03 - ETA: 1:38:19 - loss: 1.0305 - dice_coef: 0.03 - ETA: 1:38:09 - loss: 1.0304 - dice_coef: 0.03 - ETA: 1:37:58 - loss: 1.0304 - dice_coef: 0.03 - ETA: 1:37:47 - loss: 1.0304 - dice_coef: 0.03 - ETA: 1:37:36 - loss: 1.0304 - dice_coef: 0.03 - ETA: 1:37:25 - loss: 1.0303 - dice_coef: 0.03 - ETA: 1:37:14 - loss: 1.0303 - dice_coef: 0.03 - ETA: 1:37:03 - loss: 1.0302 - dice_coef: 0.03 - ETA: 1:36:52 - loss: 1.0302 - dice_coef: 0.03 - ETA: 1:36:41 - loss: 1.0302 - dice_coef: 0.03 - ETA: 1:36:31 - loss: 1.0302 - dice_coef: 0.03 - ETA: 1:36:20 - loss: 1.0302 - dice_coef: 0.03 - ETA: 1:36:09 - loss: 1.0301 - dice_coef: 0.03 - ETA: 1:35:58 - loss: 1.0301 - dice_coef: 0.03 - ETA: 1:35:47 - loss: 1.0301 - dice_coef: 0.03 - ETA: 1:35:37 - loss: 1.0300 - dice_coef: 0.03 - ETA: 1:35:26 - loss: 1.0300 - dice_coef: 0.03 - ETA: 1:35:15 - loss: 1.0299 - dice_coef: 0.03 - ETA: 1:35:04 - loss: 1.0298 - dice_coef: 0.03 - ETA: 1:34:53 - loss: 1.0298 - dice_coef: 0.0305"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 680/1068 [==================>...........] - ETA: 1:34:42 - loss: 1.0297 - dice_coef: 0.03 - ETA: 1:34:32 - loss: 1.0297 - dice_coef: 0.03 - ETA: 1:34:21 - loss: 1.0296 - dice_coef: 0.03 - ETA: 1:34:10 - loss: 1.0296 - dice_coef: 0.03 - ETA: 1:33:59 - loss: 1.0296 - dice_coef: 0.03 - ETA: 1:33:48 - loss: 1.0295 - dice_coef: 0.03 - ETA: 1:33:38 - loss: 1.0294 - dice_coef: 0.03 - ETA: 1:33:27 - loss: 1.0294 - dice_coef: 0.03 - ETA: 1:33:16 - loss: 1.0294 - dice_coef: 0.03 - ETA: 1:33:05 - loss: 1.0294 - dice_coef: 0.03 - ETA: 1:32:54 - loss: 1.0294 - dice_coef: 0.03 - ETA: 1:32:44 - loss: 1.0293 - dice_coef: 0.03 - ETA: 1:32:33 - loss: 1.0293 - dice_coef: 0.03 - ETA: 1:32:22 - loss: 1.0293 - dice_coef: 0.03 - ETA: 1:32:12 - loss: 1.0292 - dice_coef: 0.03 - ETA: 1:32:01 - loss: 1.0292 - dice_coef: 0.03 - ETA: 1:31:50 - loss: 1.0292 - dice_coef: 0.03 - ETA: 1:31:39 - loss: 1.0291 - dice_coef: 0.03 - ETA: 1:31:29 - loss: 1.0290 - dice_coef: 0.03 - ETA: 1:31:18 - loss: 1.0290 - dice_coef: 0.03 - ETA: 1:31:07 - loss: 1.0290 - dice_coef: 0.03 - ETA: 1:30:57 - loss: 1.0290 - dice_coef: 0.03 - ETA: 1:30:46 - loss: 1.0290 - dice_coef: 0.03 - ETA: 1:30:35 - loss: 1.0290 - dice_coef: 0.03 - ETA: 1:30:24 - loss: 1.0289 - dice_coef: 0.03 - ETA: 1:30:14 - loss: 1.0288 - dice_coef: 0.03 - ETA: 1:30:03 - loss: 1.0289 - dice_coef: 0.03 - ETA: 1:29:53 - loss: 1.0288 - dice_coef: 0.03 - ETA: 1:29:42 - loss: 1.0288 - dice_coef: 0.03 - ETA: 1:29:31 - loss: 1.0288 - dice_coef: 0.03 - ETA: 1:29:20 - loss: 1.0288 - dice_coef: 0.03 - ETA: 1:29:10 - loss: 1.0287 - dice_coef: 0.03 - ETA: 1:28:59 - loss: 1.0287 - dice_coef: 0.03 - ETA: 1:28:48 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:28:38 - loss: 1.0287 - dice_coef: 0.03 - ETA: 1:28:27 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:28:17 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:28:06 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:27:56 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:27:45 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:27:34 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:27:24 - loss: 1.0286 - dice_coef: 0.03 - ETA: 1:27:13 - loss: 1.0285 - dice_coef: 0.03 - ETA: 1:27:02 - loss: 1.0285 - dice_coef: 0.03 - ETA: 1:26:52 - loss: 1.0284 - dice_coef: 0.03 - ETA: 1:26:41 - loss: 1.0285 - dice_coef: 0.03 - ETA: 1:26:31 - loss: 1.0284 - dice_coef: 0.03 - ETA: 1:26:20 - loss: 1.0284 - dice_coef: 0.03 - ETA: 1:26:10 - loss: 1.0283 - dice_coef: 0.03 - ETA: 1:25:59 - loss: 1.0284 - dice_coef: 0.03 - ETA: 1:25:49 - loss: 1.0284 - dice_coef: 0.03 - ETA: 1:25:38 - loss: 1.0283 - dice_coef: 0.03 - ETA: 1:25:28 - loss: 1.0283 - dice_coef: 0.03 - ETA: 1:25:18 - loss: 1.0283 - dice_coef: 0.03 - ETA: 1:25:08 - loss: 1.0282 - dice_coef: 0.03 - ETA: 1:24:58 - loss: 1.0282 - dice_coef: 0.03 - ETA: 1:24:48 - loss: 1.0281 - dice_coef: 0.03 - ETA: 1:24:38 - loss: 1.0281 - dice_coef: 0.03 - ETA: 1:24:28 - loss: 1.0280 - dice_coef: 0.03 - ETA: 1:24:18 - loss: 1.0280 - dice_coef: 0.03 - ETA: 1:24:08 - loss: 1.0280 - dice_coef: 0.03 - ETA: 1:23:58 - loss: 1.0279 - dice_coef: 0.03 - ETA: 1:23:48 - loss: 1.0278 - dice_coef: 0.03 - ETA: 1:23:37 - loss: 1.0278 - dice_coef: 0.03 - ETA: 1:23:28 - loss: 1.0278 - dice_coef: 0.03 - ETA: 1:23:18 - loss: 1.0277 - dice_coef: 0.03 - ETA: 1:23:08 - loss: 1.0277 - dice_coef: 0.03 - ETA: 1:22:58 - loss: 1.0276 - dice_coef: 0.03 - ETA: 1:22:48 - loss: 1.0276 - dice_coef: 0.03 - ETA: 1:22:38 - loss: 1.0275 - dice_coef: 0.03 - ETA: 1:22:28 - loss: 1.0274 - dice_coef: 0.03 - ETA: 1:22:18 - loss: 1.0273 - dice_coef: 0.03 - ETA: 1:22:08 - loss: 1.0273 - dice_coef: 0.03 - ETA: 1:21:58 - loss: 1.0273 - dice_coef: 0.03 - ETA: 1:21:48 - loss: 1.0274 - dice_coef: 0.03 - ETA: 1:21:37 - loss: 1.0273 - dice_coef: 0.03 - ETA: 1:21:27 - loss: 1.0272 - dice_coef: 0.03 - ETA: 1:21:17 - loss: 1.0272 - dice_coef: 0.03 - ETA: 1:21:07 - loss: 1.0271 - dice_coef: 0.03 - ETA: 1:20:57 - loss: 1.0270 - dice_coef: 0.03 - ETA: 1:20:47 - loss: 1.0270 - dice_coef: 0.03 - ETA: 1:20:38 - loss: 1.0270 - dice_coef: 0.03 - ETA: 1:20:28 - loss: 1.0269 - dice_coef: 0.03 - ETA: 1:20:17 - loss: 1.0269 - dice_coef: 0.03 - ETA: 1:20:07 - loss: 1.0268 - dice_coef: 0.03 - ETA: 1:19:57 - loss: 1.0268 - dice_coef: 0.03 - ETA: 1:19:47 - loss: 1.0267 - dice_coef: 0.03 - ETA: 1:19:37 - loss: 1.0267 - dice_coef: 0.03 - ETA: 1:19:27 - loss: 1.0266 - dice_coef: 0.03 - ETA: 1:19:17 - loss: 1.0265 - dice_coef: 0.03 - ETA: 1:19:07 - loss: 1.0265 - dice_coef: 0.03 - ETA: 1:18:57 - loss: 1.0265 - dice_coef: 0.03 - ETA: 1:18:47 - loss: 1.0264 - dice_coef: 0.03 - ETA: 1:18:37 - loss: 1.0264 - dice_coef: 0.03 - ETA: 1:18:26 - loss: 1.0263 - dice_coef: 0.03 - ETA: 1:18:16 - loss: 1.0263 - dice_coef: 0.03 - ETA: 1:18:06 - loss: 1.0264 - dice_coef: 0.03 - ETA: 1:17:56 - loss: 1.0264 - dice_coef: 0.03 - ETA: 1:17:46 - loss: 1.0264 - dice_coef: 0.03 - ETA: 1:17:36 - loss: 1.0263 - dice_coef: 0.03 - ETA: 1:17:26 - loss: 1.0263 - dice_coef: 0.03 - ETA: 1:17:16 - loss: 1.0263 - dice_coef: 0.03 - ETA: 1:17:06 - loss: 1.0262 - dice_coef: 0.03 - ETA: 1:16:55 - loss: 1.0262 - dice_coef: 0.03 - ETA: 1:16:45 - loss: 1.0261 - dice_coef: 0.03 - ETA: 1:16:35 - loss: 1.0261 - dice_coef: 0.03 - ETA: 1:16:25 - loss: 1.0260 - dice_coef: 0.03 - ETA: 1:16:15 - loss: 1.0260 - dice_coef: 0.03 - ETA: 1:16:04 - loss: 1.0260 - dice_coef: 0.03 - ETA: 1:15:54 - loss: 1.0259 - dice_coef: 0.03 - ETA: 1:15:43 - loss: 1.0258 - dice_coef: 0.03 - ETA: 1:15:33 - loss: 1.0257 - dice_coef: 0.03 - ETA: 1:15:22 - loss: 1.0257 - dice_coef: 0.03 - ETA: 1:15:12 - loss: 1.0256 - dice_coef: 0.03 - ETA: 1:15:01 - loss: 1.0256 - dice_coef: 0.03 - ETA: 1:14:51 - loss: 1.0256 - dice_coef: 0.03 - ETA: 1:14:40 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:14:30 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:14:19 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:14:09 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:13:58 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:13:48 - loss: 1.0254 - dice_coef: 0.03 - ETA: 1:13:37 - loss: 1.0254 - dice_coef: 0.03 - ETA: 1:13:27 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:13:16 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:13:06 - loss: 1.0255 - dice_coef: 0.03 - ETA: 1:12:55 - loss: 1.0254 - dice_coef: 0.03 - ETA: 1:12:45 - loss: 1.0254 - dice_coef: 0.03 - ETA: 1:12:34 - loss: 1.0254 - dice_coef: 0.03 - ETA: 1:12:24 - loss: 1.0253 - dice_coef: 0.03 - ETA: 1:12:13 - loss: 1.0253 - dice_coef: 0.03 - ETA: 1:12:03 - loss: 1.0253 - dice_coef: 0.03 - ETA: 1:11:53 - loss: 1.0253 - dice_coef: 0.03 - ETA: 1:11:42 - loss: 1.0253 - dice_coef: 0.03 - ETA: 1:11:32 - loss: 1.0253 - dice_coef: 0.03 - ETA: 1:11:21 - loss: 1.0252 - dice_coef: 0.03 - ETA: 1:11:11 - loss: 1.0252 - dice_coef: 0.03 - ETA: 1:11:00 - loss: 1.0251 - dice_coef: 0.03 - ETA: 1:10:50 - loss: 1.0250 - dice_coef: 0.03 - ETA: 1:10:40 - loss: 1.0250 - dice_coef: 0.03 - ETA: 1:10:29 - loss: 1.0250 - dice_coef: 0.03 - ETA: 1:10:19 - loss: 1.0250 - dice_coef: 0.03 - ETA: 1:10:08 - loss: 1.0250 - dice_coef: 0.03 - ETA: 1:09:58 - loss: 1.0250 - dice_coef: 0.03 - ETA: 1:09:48 - loss: 1.0249 - dice_coef: 0.03 - ETA: 1:09:37 - loss: 1.0249 - dice_coef: 0.03 - ETA: 1:09:27 - loss: 1.0249 - dice_coef: 0.03 - ETA: 1:09:17 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:09:07 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:08:56 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:08:46 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:08:36 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:08:25 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:08:15 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:08:04 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:07:54 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:07:44 - loss: 1.0248 - dice_coef: 0.03 - ETA: 1:07:33 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:07:23 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:07:12 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:07:02 - loss: 1.0247 - dice_coef: 0.03 - ETA: 1:06:52 - loss: 1.0246 - dice_coef: 0.03 - ETA: 1:06:41 - loss: 1.0246 - dice_coef: 0.03 - ETA: 1:06:31 - loss: 1.0246 - dice_coef: 0.03 - ETA: 1:06:20 - loss: 1.0246 - dice_coef: 0.03 - ETA: 1:06:10 - loss: 1.0246 - dice_coef: 0.03 - ETA: 1:06:00 - loss: 1.0245 - dice_coef: 0.03 - ETA: 1:05:49 - loss: 1.0245 - dice_coef: 0.03 - ETA: 1:05:39 - loss: 1.0245 - dice_coef: 0.03 - ETA: 1:05:29 - loss: 1.0244 - dice_coef: 0.0327"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 856/1068 [=======================>......] - ETA: 1:05:18 - loss: 1.0244 - dice_coef: 0.03 - ETA: 1:05:08 - loss: 1.0244 - dice_coef: 0.03 - ETA: 1:04:58 - loss: 1.0244 - dice_coef: 0.03 - ETA: 1:04:47 - loss: 1.0244 - dice_coef: 0.03 - ETA: 1:04:37 - loss: 1.0243 - dice_coef: 0.03 - ETA: 1:04:27 - loss: 1.0243 - dice_coef: 0.03 - ETA: 1:04:16 - loss: 1.0243 - dice_coef: 0.03 - ETA: 1:04:06 - loss: 1.0243 - dice_coef: 0.03 - ETA: 1:03:56 - loss: 1.0242 - dice_coef: 0.03 - ETA: 1:03:45 - loss: 1.0242 - dice_coef: 0.03 - ETA: 1:03:35 - loss: 1.0241 - dice_coef: 0.03 - ETA: 1:03:25 - loss: 1.0241 - dice_coef: 0.03 - ETA: 1:03:14 - loss: 1.0241 - dice_coef: 0.03 - ETA: 1:03:04 - loss: 1.0240 - dice_coef: 0.03 - ETA: 1:02:54 - loss: 1.0241 - dice_coef: 0.03 - ETA: 1:02:43 - loss: 1.0241 - dice_coef: 0.03 - ETA: 1:02:33 - loss: 1.0240 - dice_coef: 0.03 - ETA: 1:02:23 - loss: 1.0240 - dice_coef: 0.03 - ETA: 1:02:12 - loss: 1.0240 - dice_coef: 0.03 - ETA: 1:02:02 - loss: 1.0239 - dice_coef: 0.03 - ETA: 1:01:52 - loss: 1.0239 - dice_coef: 0.03 - ETA: 1:01:41 - loss: 1.0238 - dice_coef: 0.03 - ETA: 1:01:31 - loss: 1.0238 - dice_coef: 0.03 - ETA: 1:01:21 - loss: 1.0237 - dice_coef: 0.03 - ETA: 1:01:10 - loss: 1.0236 - dice_coef: 0.03 - ETA: 1:01:00 - loss: 1.0236 - dice_coef: 0.03 - ETA: 1:00:50 - loss: 1.0236 - dice_coef: 0.03 - ETA: 1:00:39 - loss: 1.0235 - dice_coef: 0.03 - ETA: 1:00:29 - loss: 1.0235 - dice_coef: 0.03 - ETA: 1:00:19 - loss: 1.0234 - dice_coef: 0.03 - ETA: 1:00:08 - loss: 1.0234 - dice_coef: 0.03 - ETA: 59:58 - loss: 1.0234 - dice_coef: 0.0331 - ETA: 59:48 - loss: 1.0234 - dice_coef: 0.03 - ETA: 59:37 - loss: 1.0234 - dice_coef: 0.03 - ETA: 59:27 - loss: 1.0234 - dice_coef: 0.03 - ETA: 59:17 - loss: 1.0234 - dice_coef: 0.03 - ETA: 59:06 - loss: 1.0233 - dice_coef: 0.03 - ETA: 58:56 - loss: 1.0233 - dice_coef: 0.03 - ETA: 58:46 - loss: 1.0232 - dice_coef: 0.03 - ETA: 58:36 - loss: 1.0232 - dice_coef: 0.03 - ETA: 58:25 - loss: 1.0232 - dice_coef: 0.03 - ETA: 58:15 - loss: 1.0232 - dice_coef: 0.03 - ETA: 58:05 - loss: 1.0232 - dice_coef: 0.03 - ETA: 57:54 - loss: 1.0232 - dice_coef: 0.03 - ETA: 57:44 - loss: 1.0231 - dice_coef: 0.03 - ETA: 57:34 - loss: 1.0231 - dice_coef: 0.03 - ETA: 57:23 - loss: 1.0231 - dice_coef: 0.03 - ETA: 57:13 - loss: 1.0230 - dice_coef: 0.03 - ETA: 57:03 - loss: 1.0230 - dice_coef: 0.03 - ETA: 56:52 - loss: 1.0230 - dice_coef: 0.03 - ETA: 56:42 - loss: 1.0230 - dice_coef: 0.03 - ETA: 56:32 - loss: 1.0229 - dice_coef: 0.03 - ETA: 56:21 - loss: 1.0229 - dice_coef: 0.03 - ETA: 56:11 - loss: 1.0229 - dice_coef: 0.03 - ETA: 56:01 - loss: 1.0229 - dice_coef: 0.03 - ETA: 55:51 - loss: 1.0230 - dice_coef: 0.03 - ETA: 55:41 - loss: 1.0230 - dice_coef: 0.03 - ETA: 55:31 - loss: 1.0230 - dice_coef: 0.03 - ETA: 55:20 - loss: 1.0229 - dice_coef: 0.03 - ETA: 55:10 - loss: 1.0229 - dice_coef: 0.03 - ETA: 55:00 - loss: 1.0229 - dice_coef: 0.03 - ETA: 54:49 - loss: 1.0229 - dice_coef: 0.03 - ETA: 54:39 - loss: 1.0229 - dice_coef: 0.03 - ETA: 54:29 - loss: 1.0228 - dice_coef: 0.03 - ETA: 54:18 - loss: 1.0228 - dice_coef: 0.03 - ETA: 54:08 - loss: 1.0229 - dice_coef: 0.03 - ETA: 53:58 - loss: 1.0228 - dice_coef: 0.03 - ETA: 53:48 - loss: 1.0228 - dice_coef: 0.03 - ETA: 53:37 - loss: 1.0228 - dice_coef: 0.03 - ETA: 53:27 - loss: 1.0229 - dice_coef: 0.03 - ETA: 53:17 - loss: 1.0229 - dice_coef: 0.03 - ETA: 53:07 - loss: 1.0228 - dice_coef: 0.03 - ETA: 52:56 - loss: 1.0227 - dice_coef: 0.03 - ETA: 52:46 - loss: 1.0227 - dice_coef: 0.03 - ETA: 52:36 - loss: 1.0228 - dice_coef: 0.03 - ETA: 52:26 - loss: 1.0228 - dice_coef: 0.03 - ETA: 52:15 - loss: 1.0228 - dice_coef: 0.03 - ETA: 52:05 - loss: 1.0227 - dice_coef: 0.03 - ETA: 51:55 - loss: 1.0227 - dice_coef: 0.03 - ETA: 51:44 - loss: 1.0227 - dice_coef: 0.03 - ETA: 51:34 - loss: 1.0226 - dice_coef: 0.03 - ETA: 51:24 - loss: 1.0226 - dice_coef: 0.03 - ETA: 51:14 - loss: 1.0226 - dice_coef: 0.03 - ETA: 51:04 - loss: 1.0225 - dice_coef: 0.03 - ETA: 50:53 - loss: 1.0225 - dice_coef: 0.03 - ETA: 50:43 - loss: 1.0225 - dice_coef: 0.03 - ETA: 50:33 - loss: 1.0224 - dice_coef: 0.03 - ETA: 50:23 - loss: 1.0225 - dice_coef: 0.03 - ETA: 50:12 - loss: 1.0225 - dice_coef: 0.03 - ETA: 50:02 - loss: 1.0224 - dice_coef: 0.03 - ETA: 49:52 - loss: 1.0224 - dice_coef: 0.03 - ETA: 49:42 - loss: 1.0224 - dice_coef: 0.03 - ETA: 49:32 - loss: 1.0222 - dice_coef: 0.03 - ETA: 49:21 - loss: 1.0222 - dice_coef: 0.03 - ETA: 49:11 - loss: 1.0222 - dice_coef: 0.03 - ETA: 49:01 - loss: 1.0221 - dice_coef: 0.03 - ETA: 48:51 - loss: 1.0220 - dice_coef: 0.03 - ETA: 48:40 - loss: 1.0220 - dice_coef: 0.03 - ETA: 48:30 - loss: 1.0220 - dice_coef: 0.03 - ETA: 48:20 - loss: 1.0220 - dice_coef: 0.03 - ETA: 48:10 - loss: 1.0220 - dice_coef: 0.03 - ETA: 48:00 - loss: 1.0220 - dice_coef: 0.03 - ETA: 47:49 - loss: 1.0219 - dice_coef: 0.03 - ETA: 47:39 - loss: 1.0219 - dice_coef: 0.03 - ETA: 47:29 - loss: 1.0220 - dice_coef: 0.03 - ETA: 47:19 - loss: 1.0220 - dice_coef: 0.03 - ETA: 47:09 - loss: 1.0220 - dice_coef: 0.03 - ETA: 46:58 - loss: 1.0220 - dice_coef: 0.03 - ETA: 46:48 - loss: 1.0221 - dice_coef: 0.03 - ETA: 46:38 - loss: 1.0220 - dice_coef: 0.03 - ETA: 46:28 - loss: 1.0220 - dice_coef: 0.03 - ETA: 46:18 - loss: 1.0220 - dice_coef: 0.03 - ETA: 46:07 - loss: 1.0220 - dice_coef: 0.03 - ETA: 45:57 - loss: 1.0220 - dice_coef: 0.03 - ETA: 45:47 - loss: 1.0220 - dice_coef: 0.03 - ETA: 45:37 - loss: 1.0220 - dice_coef: 0.03 - ETA: 45:26 - loss: 1.0219 - dice_coef: 0.03 - ETA: 45:16 - loss: 1.0219 - dice_coef: 0.03 - ETA: 45:06 - loss: 1.0218 - dice_coef: 0.03 - ETA: 44:56 - loss: 1.0218 - dice_coef: 0.03 - ETA: 44:46 - loss: 1.0218 - dice_coef: 0.03 - ETA: 44:36 - loss: 1.0218 - dice_coef: 0.03 - ETA: 44:25 - loss: 1.0218 - dice_coef: 0.03 - ETA: 44:15 - loss: 1.0217 - dice_coef: 0.03 - ETA: 44:05 - loss: 1.0218 - dice_coef: 0.03 - ETA: 43:55 - loss: 1.0216 - dice_coef: 0.03 - ETA: 43:45 - loss: 1.0215 - dice_coef: 0.03 - ETA: 43:35 - loss: 1.0215 - dice_coef: 0.03 - ETA: 43:24 - loss: 1.0215 - dice_coef: 0.03 - ETA: 43:14 - loss: 1.0215 - dice_coef: 0.03 - ETA: 43:04 - loss: 1.0215 - dice_coef: 0.03 - ETA: 42:54 - loss: 1.0215 - dice_coef: 0.03 - ETA: 42:44 - loss: 1.0215 - dice_coef: 0.03 - ETA: 42:33 - loss: 1.0215 - dice_coef: 0.03 - ETA: 42:23 - loss: 1.0215 - dice_coef: 0.03 - ETA: 42:13 - loss: 1.0215 - dice_coef: 0.03 - ETA: 42:03 - loss: 1.0215 - dice_coef: 0.03 - ETA: 41:53 - loss: 1.0215 - dice_coef: 0.03 - ETA: 41:43 - loss: 1.0215 - dice_coef: 0.03 - ETA: 41:32 - loss: 1.0215 - dice_coef: 0.03 - ETA: 41:22 - loss: 1.0215 - dice_coef: 0.03 - ETA: 41:12 - loss: 1.0215 - dice_coef: 0.03 - ETA: 41:02 - loss: 1.0215 - dice_coef: 0.03 - ETA: 40:52 - loss: 1.0214 - dice_coef: 0.03 - ETA: 40:42 - loss: 1.0214 - dice_coef: 0.03 - ETA: 40:31 - loss: 1.0214 - dice_coef: 0.03 - ETA: 40:21 - loss: 1.0214 - dice_coef: 0.03 - ETA: 40:11 - loss: 1.0214 - dice_coef: 0.03 - ETA: 40:01 - loss: 1.0214 - dice_coef: 0.03 - ETA: 39:51 - loss: 1.0214 - dice_coef: 0.03 - ETA: 39:41 - loss: 1.0214 - dice_coef: 0.03 - ETA: 39:31 - loss: 1.0214 - dice_coef: 0.03 - ETA: 39:21 - loss: 1.0214 - dice_coef: 0.03 - ETA: 39:11 - loss: 1.0213 - dice_coef: 0.03 - ETA: 39:01 - loss: 1.0213 - dice_coef: 0.03 - ETA: 38:51 - loss: 1.0213 - dice_coef: 0.03 - ETA: 38:41 - loss: 1.0213 - dice_coef: 0.03 - ETA: 38:31 - loss: 1.0212 - dice_coef: 0.03 - ETA: 38:21 - loss: 1.0212 - dice_coef: 0.03 - ETA: 38:11 - loss: 1.0212 - dice_coef: 0.03 - ETA: 38:01 - loss: 1.0211 - dice_coef: 0.03 - ETA: 37:51 - loss: 1.0211 - dice_coef: 0.03 - ETA: 37:41 - loss: 1.0211 - dice_coef: 0.03 - ETA: 37:31 - loss: 1.0211 - dice_coef: 0.03 - ETA: 37:21 - loss: 1.0211 - dice_coef: 0.03 - ETA: 37:11 - loss: 1.0211 - dice_coef: 0.03 - ETA: 37:01 - loss: 1.0211 - dice_coef: 0.03 - ETA: 36:51 - loss: 1.0211 - dice_coef: 0.03 - ETA: 36:41 - loss: 1.0211 - dice_coef: 0.03 - ETA: 36:31 - loss: 1.0211 - dice_coef: 0.03 - ETA: 36:21 - loss: 1.0211 - dice_coef: 0.03 - ETA: 36:11 - loss: 1.0211 - dice_coef: 0.03 - ETA: 36:01 - loss: 1.0211 - dice_coef: 0.03 - ETA: 35:51 - loss: 1.0211 - dice_coef: 0.03 - ETA: 35:41 - loss: 1.0211 - dice_coef: 0.03 - ETA: 35:31 - loss: 1.0211 - dice_coef: 0.0346"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034/1068 [============================>.] - ETA: 35:21 - loss: 1.0210 - dice_coef: 0.03 - ETA: 35:11 - loss: 1.0211 - dice_coef: 0.03 - ETA: 35:01 - loss: 1.0210 - dice_coef: 0.03 - ETA: 34:51 - loss: 1.0210 - dice_coef: 0.03 - ETA: 34:41 - loss: 1.0210 - dice_coef: 0.03 - ETA: 34:31 - loss: 1.0210 - dice_coef: 0.03 - ETA: 34:21 - loss: 1.0210 - dice_coef: 0.03 - ETA: 34:11 - loss: 1.0210 - dice_coef: 0.03 - ETA: 34:01 - loss: 1.0209 - dice_coef: 0.03 - ETA: 33:51 - loss: 1.0209 - dice_coef: 0.03 - ETA: 33:41 - loss: 1.0209 - dice_coef: 0.03 - ETA: 33:31 - loss: 1.0209 - dice_coef: 0.03 - ETA: 33:21 - loss: 1.0209 - dice_coef: 0.03 - ETA: 33:11 - loss: 1.0209 - dice_coef: 0.03 - ETA: 33:01 - loss: 1.0209 - dice_coef: 0.03 - ETA: 32:51 - loss: 1.0209 - dice_coef: 0.03 - ETA: 32:41 - loss: 1.0208 - dice_coef: 0.03 - ETA: 32:31 - loss: 1.0208 - dice_coef: 0.03 - ETA: 32:21 - loss: 1.0208 - dice_coef: 0.03 - ETA: 32:11 - loss: 1.0208 - dice_coef: 0.03 - ETA: 32:01 - loss: 1.0208 - dice_coef: 0.03 - ETA: 31:51 - loss: 1.0207 - dice_coef: 0.03 - ETA: 31:41 - loss: 1.0207 - dice_coef: 0.03 - ETA: 31:31 - loss: 1.0207 - dice_coef: 0.03 - ETA: 31:21 - loss: 1.0207 - dice_coef: 0.03 - ETA: 31:11 - loss: 1.0206 - dice_coef: 0.03 - ETA: 31:01 - loss: 1.0206 - dice_coef: 0.03 - ETA: 30:51 - loss: 1.0206 - dice_coef: 0.03 - ETA: 30:41 - loss: 1.0206 - dice_coef: 0.03 - ETA: 30:31 - loss: 1.0205 - dice_coef: 0.03 - ETA: 30:21 - loss: 1.0205 - dice_coef: 0.03 - ETA: 30:11 - loss: 1.0205 - dice_coef: 0.03 - ETA: 30:01 - loss: 1.0205 - dice_coef: 0.03 - ETA: 29:51 - loss: 1.0204 - dice_coef: 0.03 - ETA: 29:40 - loss: 1.0204 - dice_coef: 0.03 - ETA: 29:30 - loss: 1.0205 - dice_coef: 0.03 - ETA: 29:20 - loss: 1.0204 - dice_coef: 0.03 - ETA: 29:10 - loss: 1.0204 - dice_coef: 0.03 - ETA: 29:00 - loss: 1.0204 - dice_coef: 0.03 - ETA: 28:50 - loss: 1.0204 - dice_coef: 0.03 - ETA: 28:40 - loss: 1.0203 - dice_coef: 0.03 - ETA: 28:29 - loss: 1.0202 - dice_coef: 0.03 - ETA: 28:19 - loss: 1.0202 - dice_coef: 0.03 - ETA: 28:09 - loss: 1.0202 - dice_coef: 0.03 - ETA: 27:59 - loss: 1.0201 - dice_coef: 0.03 - ETA: 27:49 - loss: 1.0201 - dice_coef: 0.03 - ETA: 27:39 - loss: 1.0201 - dice_coef: 0.03 - ETA: 27:29 - loss: 1.0200 - dice_coef: 0.03 - ETA: 27:19 - loss: 1.0201 - dice_coef: 0.03 - ETA: 27:08 - loss: 1.0201 - dice_coef: 0.03 - ETA: 26:58 - loss: 1.0200 - dice_coef: 0.03 - ETA: 26:48 - loss: 1.0200 - dice_coef: 0.03 - ETA: 26:38 - loss: 1.0200 - dice_coef: 0.03 - ETA: 26:28 - loss: 1.0199 - dice_coef: 0.03 - ETA: 26:18 - loss: 1.0198 - dice_coef: 0.03 - ETA: 26:08 - loss: 1.0198 - dice_coef: 0.03 - ETA: 25:58 - loss: 1.0198 - dice_coef: 0.03 - ETA: 25:48 - loss: 1.0198 - dice_coef: 0.03 - ETA: 25:38 - loss: 1.0198 - dice_coef: 0.03 - ETA: 25:29 - loss: 1.0198 - dice_coef: 0.03 - ETA: 25:19 - loss: 1.0197 - dice_coef: 0.03 - ETA: 25:09 - loss: 1.0197 - dice_coef: 0.03 - ETA: 24:59 - loss: 1.0197 - dice_coef: 0.03 - ETA: 24:49 - loss: 1.0197 - dice_coef: 0.03 - ETA: 24:39 - loss: 1.0196 - dice_coef: 0.03 - ETA: 24:29 - loss: 1.0196 - dice_coef: 0.03 - ETA: 24:19 - loss: 1.0196 - dice_coef: 0.03 - ETA: 24:10 - loss: 1.0196 - dice_coef: 0.03 - ETA: 24:00 - loss: 1.0196 - dice_coef: 0.03 - ETA: 23:50 - loss: 1.0196 - dice_coef: 0.03 - ETA: 23:40 - loss: 1.0196 - dice_coef: 0.03 - ETA: 23:30 - loss: 1.0195 - dice_coef: 0.03 - ETA: 23:20 - loss: 1.0195 - dice_coef: 0.03 - ETA: 23:10 - loss: 1.0195 - dice_coef: 0.03 - ETA: 22:59 - loss: 1.0195 - dice_coef: 0.03 - ETA: 22:49 - loss: 1.0194 - dice_coef: 0.03 - ETA: 22:39 - loss: 1.0194 - dice_coef: 0.03 - ETA: 22:29 - loss: 1.0195 - dice_coef: 0.03 - ETA: 22:19 - loss: 1.0194 - dice_coef: 0.03 - ETA: 22:09 - loss: 1.0194 - dice_coef: 0.03 - ETA: 21:59 - loss: 1.0194 - dice_coef: 0.03 - ETA: 21:49 - loss: 1.0194 - dice_coef: 0.03 - ETA: 21:39 - loss: 1.0193 - dice_coef: 0.03 - ETA: 21:29 - loss: 1.0193 - dice_coef: 0.03 - ETA: 21:19 - loss: 1.0192 - dice_coef: 0.03 - ETA: 21:09 - loss: 1.0193 - dice_coef: 0.03 - ETA: 20:58 - loss: 1.0193 - dice_coef: 0.03 - ETA: 20:48 - loss: 1.0193 - dice_coef: 0.03 - ETA: 20:38 - loss: 1.0193 - dice_coef: 0.03 - ETA: 20:28 - loss: 1.0193 - dice_coef: 0.03 - ETA: 20:18 - loss: 1.0193 - dice_coef: 0.03 - ETA: 20:08 - loss: 1.0193 - dice_coef: 0.03 - ETA: 19:58 - loss: 1.0192 - dice_coef: 0.03 - ETA: 19:48 - loss: 1.0192 - dice_coef: 0.03 - ETA: 19:38 - loss: 1.0193 - dice_coef: 0.03 - ETA: 19:28 - loss: 1.0193 - dice_coef: 0.03 - ETA: 19:18 - loss: 1.0192 - dice_coef: 0.03 - ETA: 19:08 - loss: 1.0192 - dice_coef: 0.03 - ETA: 18:57 - loss: 1.0192 - dice_coef: 0.03 - ETA: 18:47 - loss: 1.0192 - dice_coef: 0.03 - ETA: 18:37 - loss: 1.0192 - dice_coef: 0.03 - ETA: 18:27 - loss: 1.0192 - dice_coef: 0.03 - ETA: 18:17 - loss: 1.0191 - dice_coef: 0.03 - ETA: 18:07 - loss: 1.0191 - dice_coef: 0.03 - ETA: 17:57 - loss: 1.0191 - dice_coef: 0.03 - ETA: 17:47 - loss: 1.0191 - dice_coef: 0.03 - ETA: 17:36 - loss: 1.0191 - dice_coef: 0.03 - ETA: 17:26 - loss: 1.0191 - dice_coef: 0.03 - ETA: 17:16 - loss: 1.0191 - dice_coef: 0.03 - ETA: 17:06 - loss: 1.0190 - dice_coef: 0.03 - ETA: 16:56 - loss: 1.0190 - dice_coef: 0.03 - ETA: 16:46 - loss: 1.0190 - dice_coef: 0.03 - ETA: 16:36 - loss: 1.0189 - dice_coef: 0.03 - ETA: 16:26 - loss: 1.0189 - dice_coef: 0.03 - ETA: 16:16 - loss: 1.0190 - dice_coef: 0.03 - ETA: 16:06 - loss: 1.0190 - dice_coef: 0.03 - ETA: 15:55 - loss: 1.0190 - dice_coef: 0.03 - ETA: 15:45 - loss: 1.0190 - dice_coef: 0.03 - ETA: 15:35 - loss: 1.0190 - dice_coef: 0.03 - ETA: 15:25 - loss: 1.0190 - dice_coef: 0.03 - ETA: 15:15 - loss: 1.0190 - dice_coef: 0.03 - ETA: 15:05 - loss: 1.0190 - dice_coef: 0.03 - ETA: 14:55 - loss: 1.0190 - dice_coef: 0.03 - ETA: 14:45 - loss: 1.0190 - dice_coef: 0.03 - ETA: 14:35 - loss: 1.0190 - dice_coef: 0.03 - ETA: 14:25 - loss: 1.0190 - dice_coef: 0.03 - ETA: 14:14 - loss: 1.0189 - dice_coef: 0.03 - ETA: 14:04 - loss: 1.0189 - dice_coef: 0.03 - ETA: 13:54 - loss: 1.0188 - dice_coef: 0.03 - ETA: 13:44 - loss: 1.0187 - dice_coef: 0.03 - ETA: 13:34 - loss: 1.0187 - dice_coef: 0.03 - ETA: 13:24 - loss: 1.0187 - dice_coef: 0.03 - ETA: 13:14 - loss: 1.0188 - dice_coef: 0.03 - ETA: 13:04 - loss: 1.0187 - dice_coef: 0.03 - ETA: 12:54 - loss: 1.0187 - dice_coef: 0.03 - ETA: 12:44 - loss: 1.0187 - dice_coef: 0.03 - ETA: 12:34 - loss: 1.0187 - dice_coef: 0.03 - ETA: 12:24 - loss: 1.0187 - dice_coef: 0.03 - ETA: 12:13 - loss: 1.0187 - dice_coef: 0.03 - ETA: 12:03 - loss: 1.0187 - dice_coef: 0.03 - ETA: 11:53 - loss: 1.0186 - dice_coef: 0.03 - ETA: 11:43 - loss: 1.0186 - dice_coef: 0.03 - ETA: 11:33 - loss: 1.0186 - dice_coef: 0.03 - ETA: 11:23 - loss: 1.0187 - dice_coef: 0.03 - ETA: 11:13 - loss: 1.0186 - dice_coef: 0.03 - ETA: 11:03 - loss: 1.0186 - dice_coef: 0.03 - ETA: 10:53 - loss: 1.0186 - dice_coef: 0.03 - ETA: 10:43 - loss: 1.0186 - dice_coef: 0.03 - ETA: 10:33 - loss: 1.0186 - dice_coef: 0.03 - ETA: 10:23 - loss: 1.0186 - dice_coef: 0.03 - ETA: 10:12 - loss: 1.0186 - dice_coef: 0.03 - ETA: 10:02 - loss: 1.0186 - dice_coef: 0.03 - ETA: 9:52 - loss: 1.0185 - dice_coef: 0.0357 - ETA: 9:42 - loss: 1.0186 - dice_coef: 0.035 - ETA: 9:32 - loss: 1.0185 - dice_coef: 0.035 - ETA: 9:22 - loss: 1.0185 - dice_coef: 0.035 - ETA: 9:12 - loss: 1.0185 - dice_coef: 0.035 - ETA: 9:02 - loss: 1.0186 - dice_coef: 0.035 - ETA: 8:52 - loss: 1.0186 - dice_coef: 0.035 - ETA: 8:42 - loss: 1.0185 - dice_coef: 0.035 - ETA: 8:32 - loss: 1.0185 - dice_coef: 0.035 - ETA: 8:22 - loss: 1.0185 - dice_coef: 0.035 - ETA: 8:12 - loss: 1.0185 - dice_coef: 0.035 - ETA: 8:02 - loss: 1.0185 - dice_coef: 0.035 - ETA: 7:52 - loss: 1.0185 - dice_coef: 0.035 - ETA: 7:41 - loss: 1.0185 - dice_coef: 0.035 - ETA: 7:31 - loss: 1.0185 - dice_coef: 0.035 - ETA: 7:21 - loss: 1.0185 - dice_coef: 0.035 - ETA: 7:11 - loss: 1.0185 - dice_coef: 0.035 - ETA: 7:01 - loss: 1.0185 - dice_coef: 0.035 - ETA: 6:51 - loss: 1.0185 - dice_coef: 0.035 - ETA: 6:41 - loss: 1.0185 - dice_coef: 0.035 - ETA: 6:31 - loss: 1.0184 - dice_coef: 0.035 - ETA: 6:21 - loss: 1.0184 - dice_coef: 0.035 - ETA: 6:11 - loss: 1.0184 - dice_coef: 0.035 - ETA: 6:01 - loss: 1.0184 - dice_coef: 0.035 - ETA: 5:51 - loss: 1.0184 - dice_coef: 0.035 - ETA: 5:41 - loss: 1.0184 - dice_coef: 0.0356"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - ETA: 5:31 - loss: 1.0183 - dice_coef: 0.035 - ETA: 5:21 - loss: 1.0183 - dice_coef: 0.035 - ETA: 5:11 - loss: 1.0183 - dice_coef: 0.035 - ETA: 5:01 - loss: 1.0183 - dice_coef: 0.035 - ETA: 4:51 - loss: 1.0183 - dice_coef: 0.035 - ETA: 4:41 - loss: 1.0182 - dice_coef: 0.035 - ETA: 4:30 - loss: 1.0182 - dice_coef: 0.035 - ETA: 4:20 - loss: 1.0181 - dice_coef: 0.035 - ETA: 4:10 - loss: 1.0181 - dice_coef: 0.035 - ETA: 4:00 - loss: 1.0181 - dice_coef: 0.035 - ETA: 3:50 - loss: 1.0180 - dice_coef: 0.035 - ETA: 3:40 - loss: 1.0180 - dice_coef: 0.035 - ETA: 3:30 - loss: 1.0179 - dice_coef: 0.035 - ETA: 3:20 - loss: 1.0179 - dice_coef: 0.035 - ETA: 3:10 - loss: 1.0179 - dice_coef: 0.035 - ETA: 3:00 - loss: 1.0179 - dice_coef: 0.035 - ETA: 2:50 - loss: 1.0178 - dice_coef: 0.035 - ETA: 2:40 - loss: 1.0178 - dice_coef: 0.036 - ETA: 2:30 - loss: 1.0178 - dice_coef: 0.036 - ETA: 2:20 - loss: 1.0178 - dice_coef: 0.036 - ETA: 2:10 - loss: 1.0178 - dice_coef: 0.036 - ETA: 2:00 - loss: 1.0177 - dice_coef: 0.036 - ETA: 1:50 - loss: 1.0177 - dice_coef: 0.036 - ETA: 1:40 - loss: 1.0177 - dice_coef: 0.036 - ETA: 1:30 - loss: 1.0177 - dice_coef: 0.036 - ETA: 1:20 - loss: 1.0176 - dice_coef: 0.036 - ETA: 1:10 - loss: 1.0176 - dice_coef: 0.036 - ETA: 1:00 - loss: 1.0175 - dice_coef: 0.036 - ETA: 50s - loss: 1.0175 - dice_coef: 0.036 - ETA: 40s - loss: 1.0175 - dice_coef: 0.03 - ETA: 30s - loss: 1.0175 - dice_coef: 0.03 - ETA: 20s - loss: 1.0175 - dice_coef: 0.03 - ETA: 10s - loss: 1.0175 - dice_coef: 0.03 - 11540s 11s/step - loss: 1.0175 - dice_coef: 0.0362 - val_loss: 1.0269 - val_dice_coef: 0.0480\n",
      "Epoch 2/7\n",
      "   4/1068 [..............................] - ETA: 2:55:12 - loss: 1.0162 - dice_coef: 0.05 - ETA: 2:58:27 - loss: 1.0038 - dice_coef: 0.06 - ETA: 2:59:27 - loss: 1.0083 - dice_coef: 0.04 - ETA: 2:58:51 - loss: 1.0071 - dice_coef: 0.0437"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor='val_dice_coef', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint],\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "test_df = []\n",
    "\n",
    "for i in range(0, test_imgs.shape[0], 500):\n",
    "    batch_idx = list(\n",
    "        range(i, min(test_imgs.shape[0], i + 500))\n",
    "    )\n",
    "    \n",
    "    test_generator = DataGenerator(\n",
    "        batch_idx,\n",
    "        df=test_imgs,\n",
    "        shuffle=False,\n",
    "        mode='predict',\n",
    "        base_path='../input/severstal-steel-defect-detection/test_images',\n",
    "        target_df=sub_df,\n",
    "        batch_size=1,\n",
    "        n_classes=4\n",
    "    )\n",
    "    \n",
    "    batch_pred_masks = model.predict_generator(\n",
    "        test_generator, \n",
    "        workers=1,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    for j, b in tqdm(enumerate(batch_idx)):\n",
    "        filename = test_imgs['ImageId'].iloc[b]\n",
    "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
    "        \n",
    "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
    "        pred_rles = build_rles(pred_masks)\n",
    "        \n",
    "        image_df['EncodedPixels'] = pred_rles\n",
    "        test_df.append(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat(test_df)\n",
    "test_df.drop(columns='ImageId', inplace=True)\n",
    "test_df.to_csv('test_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
